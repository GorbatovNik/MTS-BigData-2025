# Скрипт для автоматического развертования hdfs на кластере

Скрипт автоматически разворачивает минимальный Hadoop-кластер по конфигурации из `cluster.conf`.

### Основные шаги
1. Загружает `cluster.conf` и запрашивает пароли для SSH и sudo.
2. Генерирует SSH-ключ для пользователя `$ADMIN` и раскладывает его на все узлы.
3. Обновляет `/etc/hosts` на всех узлах.
4. Создаёт пользователя `$HADOOP_USER` с указанным паролем.
5. Генерирует ключи SSH для `$HADOOP_USER` и настраивает безпарольный доступ.
6. Скачивает дистрибутив Hadoop и разворачивает его на всех узлах.
7. Прописывает переменные окружения (`JAVA_HOME`, `HADOOP_HOME`, `PATH`) и `JAVA_HOME` в `hadoop-env.sh`.
8. Раскладывает конфигурационные файлы (`core-site.xml`, `hdfs-site.xml`) и создаёт список рабочих узлов (`workers`).
9. Форматирует NameNode на `$NN`.
10. Запускает HDFS (`start-dfs.sh`) и проверяет процессы через `jps`.

### Требования
- Утилиты: `sshpass`, `ssh`, `scp`, `wget`, `tar`, `jps`.
- Конфигурационные файлы `core-site.xml`, `hdfs-site.xml`, `cluster.conf` рядом со скриптом на jump-node.
- Пароли для доступа к узлам по SSH дожны совпадать
- sudo пароли на узлах должны совпадать
- Имена админ-пользователей на узлах должны соответствовать `$ADMIN` (`team` по умолчанию)

### Запуск скрипта
1) Перенесите файлы этого каталога на jump-node
2) Отредактируйте `cluster.conf`, а именно:
   - ip адреса узлов во внутренней сети
   - версия hadoop для установки
   - имя админ-пользователя

```bash
bash setup_cluster.sh
```

### Остановка кластера hadoop
```bash
bash stop_cluster.sh
```
